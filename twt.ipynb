{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/twitter_sentiment.csv', header=None, index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[2,3]].reset_index(drop=True)\n",
    "df.columns = ['sentiment', 'text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.isnull().sum()\n",
    "df.dropna(inplace=True)\n",
    "df = df[df['text'].apply(len)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_kgptalkie as ps\n",
    "\n",
    "df = ps.get_basic_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plot 2x4 grid histogram for each numerical feature\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.subplot(2,4, num_cols.get_loc(col)+1)\n",
    "\n",
    "    # use sentiment as hue to see the distribution of each numerical feature\n",
    "    # sns.distplot(df[col], label=col, color='red')\n",
    "    # sns.histplot(x=col, hue='sentiment', data=df, color='green', bins=100, kde=True)\n",
    "    sns.kdeplot(data=df, x=col, hue='sentiment', fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts().plot(kind='pie', autopct='%1.0f%%')\n",
    "\n",
    "# word cloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,20))\n",
    "\n",
    "for index, col in enumerate(df['sentiment'].unique()):\n",
    "    plt.subplot(2,2, index+1)\n",
    "    # print(col)\n",
    "    df1 = df[df['sentiment']==col]\n",
    "    data = df1['text']\n",
    "    wordcloud = WordCloud(background_color='white', stopwords=stopwords, max_words=500, max_font_size=40, scale=5).generate(str(data))\n",
    "    # fig = plt.figure(figsize=(15,15))\n",
    "    # plt.axis('off')\n",
    "    # disable ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.title(col, fontsize=40)\n",
    "    \n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# lowercase, remove url, html, punctuations, retweet\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "df['text'] = df['text'].apply(lambda x: ps.remove_urls(x))\n",
    "# df['text'] = df['text'].apply(lambda x: ps.remove_html_tags(x))\n",
    "df['text'] = df['text'].apply(lambda x: ps.remove_special_chars(x))\n",
    "df['text'] = df['text'].apply(lambda x: ps.remove_rt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59717,), (14930,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.97      0.87      0.92      2616\n",
      "    Negative       0.92      0.95      0.93      4552\n",
      "     Neutral       0.92      0.92      0.92      3679\n",
      "    Positive       0.90      0.94      0.92      4083\n",
      "\n",
      "    accuracy                           0.92     14930\n",
      "   macro avg       0.93      0.92      0.92     14930\n",
      "weighted avg       0.92      0.92      0.92     14930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model building\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', RandomForestClassifier( n_jobs=-1))])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf,open(\"twitter_sentiment.pkl\",'wb'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(['let me not upset you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['punjab '])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
